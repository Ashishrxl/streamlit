import streamlit as st
import base64
import tempfile
import io
import asyncio
import soundfile as sf
from google import genai
import requests
import wave
import numpy as np

st.set_page_config(page_title="Singify üé∂", layout="centered")
st.title("üé§ Singify")
st.caption("Record or upload a line ‚Üí Transcribe....")

# Initialize session state
if 'transcript' not in st.session_state:
    st.session_state.transcript = None
if 'vocal_path' not in st.session_state:
    st.session_state.vocal_path = None
if 'original_path' not in st.session_state:
    st.session_state.original_path = None
if 'generation_complete' not in st.session_state:
    st.session_state.generation_complete = False
if 'current_style' not in st.session_state:
    st.session_state.current_style = None
if 'current_voice' not in st.session_state:
    st.session_state.current_voice = None

# Sidebar
singing_style = st.sidebar.selectbox("Singing Style", ["Pop", "Ballad", "Rap", "Soft"])
voice_option = st.sidebar.selectbox("Voice", ["Kore", "Charon", "Fenrir", "Aoede"])

audio_bytes = None
tmp_path = None

# -------------------------
# Helper: Convert audio to WAV bytes
# -------------------------
def convert_to_wav_bytes(file_bytes):
    """
    Convert MP3/M4A/WAV audio bytes to WAV bytes using soundfile
    """
    try:
        with io.BytesIO(file_bytes) as f:
            data, samplerate = sf.read(f, always_2d=True)
        out_bytes = io.BytesIO()
        sf.write(out_bytes, data, samplerate, format='WAV')
        return out_bytes.getvalue()
    except Exception as e:
        st.error(f"Error converting audio: {e}")
        return None

# -------------------------
# Audio Input Options
# -------------------------
st.subheader("üì§ Choose Audio Input Method")

# Create tabs for different input methods
tab1, tab2 = st.tabs(["üìÅ Upload Audio File", "üéôÔ∏è Record Audio"])

with tab1:
    st.markdown("**Upload an audio file from your device**")
    uploaded = st.file_uploader(
        "Choose an audio file", 
        type=["wav", "mp3", "m4a", "ogg", "flac"],
        help="Supported formats: WAV, MP3, M4A, OGG, FLAC (Max 200MB)"
    )

    if uploaded:
        st.success(f"‚úÖ Uploaded: {uploaded.name} ({uploaded.size / 1024 / 1024:.2f} MB)")
        file_bytes = uploaded.read()
        ext = uploaded.name.split('.')[-1].lower()

        if ext != "wav":
            with st.spinner("Converting audio to WAV..."):
                audio_bytes = convert_to_wav_bytes(file_bytes)
        else:
            audio_bytes = file_bytes

        if audio_bytes:
            tmp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
            tmp_path = tmp_file.name
            with open(tmp_path, "wb") as f:
                f.write(audio_bytes)

            # Store original path in session state
            st.session_state.original_path = tmp_path

            # Show audio info
            data, samplerate = sf.read(tmp_path, always_2d=True)
            duration = len(data) / samplerate
            st.info(f"üéµ Duration: {duration:.2f}s | Sample Rate: {samplerate} Hz | Channels: {data.shape[1]}")
            st.audio(tmp_path, format="audio/wav")

with tab2:
    st.markdown("")
    
    # Option 1: Native Streamlit Audio Input (Recommended)
    st.markdown("")
    recorded_audio_native = st.audio_input("üéôÔ∏è Record your voice", key="native_recorder")
    
    if recorded_audio_native is not None:
        st.success("‚úÖ Audio recorded successfully with native recorder!")
        
        # Read the audio bytes
        audio_bytes = recorded_audio_native.read()
        recorded_audio_native.seek(0)
        
        # Save to tmp file
        tmp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        tmp_path = tmp_file.name
        with open(tmp_path, "wb") as f:
            f.write(audio_bytes)

        st.session_state.original_path = tmp_path

        try:
            data, samplerate = sf.read(tmp_path, always_2d=True)
            duration = len(data) / samplerate
            st.info(f"üéµ Duration: {duration:.2f}s | Sample Rate: {samplerate} Hz")
            st.audio(tmp_path, format="audio/wav")
        except Exception as e:
            st.warning(f"Could not read audio properties: {e}")
            st.audio(recorded_audio_native, format="audio/wav")

    st.markdown("---")

    # Option 2: Enhanced recorder from streamlit-audio-recorder package
    st.markdown("**Option 2: Enhanced Audio Recorder** (Alternative)")

    try:
        from streamlit_audio_recorder import audio_recorder

        recorded_audio_enhanced = audio_recorder(
            text="Click to record",
            recording_color="#e8b62c",
            neutral_color="#6aa36f",
            icon_name="microphone",
            icon_size="2x",
            key="enhanced_recorder"
        )

        if recorded_audio_enhanced is not None:
            st.success("‚úÖ Audio recorded successfully with enhanced recorder!")
            audio_bytes = recorded_audio_enhanced

            tmp_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
            tmp_path = tmp_file.name
            with open(tmp_path, "wb") as f:
                f.write(audio_bytes)

            st.session_state.original_path = tmp_path

            try:
                data, samplerate = sf.read(tmp_path, always_2d=True)
                duration = len(data) / samplerate
                st.info(f"üéµ Duration: {duration:.2f}s | Sample Rate: {samplerate} Hz")
                st.audio(tmp_path, format="audio/wav")
            except Exception as e:
                st.warning(f"Could not read audio properties: {e}")
                st.audio(recorded_audio_enhanced, format="audio/wav")

    except ImportError:
        st.warning("‚ö†Ô∏è Enhanced audio recording package `streamlit-audio-recorder` not found.")
        st.info(
            """
            To enable enhanced recording, install it with:
            ```
            pip install streamlit-audio-recorder
            ```
            For now, please use the native Streamlit audio input above.
            """
        )

# -------------------------
# Additional Upload Options
# -------------------------
st.subheader("üìé Additional Options")

col1, col2, col3 = st.columns(3)
with col1:
    if st.button("üóëÔ∏è Clear Audio"):
        audio_bytes = None
        tmp_path = None
        # Clear session state
        st.session_state.transcript = None
        st.session_state.vocal_path = None
        st.session_state.original_path = None
        st.session_state.generation_complete = False
        st.session_state.current_style = None
        st.session_state.current_voice = None
        st.rerun()

with col2:
    if (audio_bytes or st.session_state.original_path) and st.button("‚ÑπÔ∏è Audio Info"):
        path_to_check = tmp_path if tmp_path else st.session_state.original_path
        if path_to_check:
            try:
                data, samplerate = sf.read(path_to_check, always_2d=True)
                duration = len(data) / samplerate
                file_size = len(audio_bytes) / 1024 / 1024 if audio_bytes else 0

                st.info(f"""
                **Audio Information:**
                - Duration: {duration:.2f} seconds
                - Sample Rate: {samplerate} Hz
                - Channels: {data.shape[1]}
                - File Size: {file_size:.2f} MB
                - Format: WAV
                """)
            except Exception as e:
                st.error(f"Error reading audio info: {e}")

with col3:
    if st.session_state.generation_complete and st.button("üÜï Generate New"):
        st.session_state.transcript = None
        st.session_state.vocal_path = None
        st.session_state.generation_complete = False
        st.session_state.current_style = None
        st.session_state.current_voice = None
        st.rerun()

# -------------------------
# Helper: Corrected Gemini TTS using official API
# -------------------------
async def synthesize_speech(text_prompt, voice_name="Kore"):
    """
    Correct Gemini TTS API call using official documentation structure
    """
    url = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-tts:generateContent"
    headers = {
        "x-goog-api-key": st.secrets['GOOGLE_API_KEY'],
        "Content-Type": "application/json"
    }

    data = {
        "contents": [{
            "parts": [{
                "text": text_prompt
            }]
        }],
        "generationConfig": {
            "responseModalities": ["AUDIO"],
            "speechConfig": {
                "voiceConfig": {
                    "prebuiltVoiceConfig": {
                        "voiceName": voice_name
                    }
                }
            }
        }
    }

    loop = asyncio.get_event_loop()
    response = await loop.run_in_executor(
        None, lambda: requests.post(url, headers=headers, json=data)
    )
    response.raise_for_status()

    response_json = response.json()
    audio_base64 = response_json["candidates"][0]["content"]["parts"][0]["inlineData"]["data"]

    if audio_base64 is None:
        raise ValueError("No audio returned.")

    return base64.b64decode(audio_base64)

# -------------------------
# Helper: Convert PCM to WAV
# -------------------------
def pcm_to_wav(pcm_data, channels=1, sample_rate=24000, sample_width=2):
    """Convert raw PCM data to WAV format"""
    wav_buffer = io.BytesIO()
    with wave.open(wav_buffer, 'wb') as wav_file:
        wav_file.setnchannels(channels)
        wav_file.setsampwidth(sample_width) 
        wav_file.setframerate(sample_rate)
        wav_file.writeframes(pcm_data)
    return wav_buffer.getvalue()

# -------------------------
# Step 2 & 3: Transcribe & TTS with progress
# -------------------------
async def transcribe_and_sing():
    client = genai.Client()

    progress_text = st.empty()
    progress_bar = st.progress(0)

    # Use tmp_path or stored original_path
    audio_path = tmp_path if tmp_path else st.session_state.original_path

    if not audio_path:
        st.error("No audio file available")
        return

    # Read audio for processing
    if audio_bytes:
        current_audio_bytes = audio_bytes
    else:
        with open(audio_path, "rb") as f:
            current_audio_bytes = f.read()

    # Estimate duration
    data, samplerate = sf.read(audio_path, always_2d=True)
    duration = len(data) / samplerate
    step_transcribe = 50 / max(duration, 1)
    step_tts = 50 / max(duration, 1)

    # --- Transcription ---
    progress_text.text("üî§ Transcribing...")
    try:
        resp = client.models.generate_content(
            model="gemini-1.5-flash",
            contents=[
                {"role": "user", "parts": [
                    {"text": "Please transcribe this speech accurately."},
                    {"inline_data": {"mime_type": "audio/wav", "data": base64.b64encode(current_audio_bytes).decode()}}
                ]}
            ]
        )
        transcript = resp.text.strip()
        st.session_state.transcript = transcript  # Store in session state
    except Exception as e:
        st.error(f"‚ùå Transcription failed: {e}")
        return

    # Simulate progress for transcription
    for i in range(int(max(duration, 1))):
        progress_bar.progress(min(int((i + 1) * step_transcribe), 50))
        await asyncio.sleep(0.05)

    st.success("‚úÖ Transcription complete!")

    # --- TTS with natural language prompt ---
    progress_text.text(f"üéµ Generating... {singing_style}")

    tts_prompt = f"Sing these words in a {singing_style.lower()} style with emotion and musical expression: {transcript}"

    try:
        tts_task = asyncio.create_task(synthesize_speech(tts_prompt, voice_name=voice_option))
        for i in range(int(max(duration, 1))):
            progress_bar.progress(min(50 + int((i + 1) * step_tts), 100))
            await asyncio.sleep(0.05)

        pcm_data = await tts_task
        vocal_bytes = pcm_to_wav(pcm_data)

        progress_bar.progress(100)
        progress_text.text("üé∂ Your sung version is ready!")

        # Save vocal and store in session state
        vocal_file = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        vocal_path = vocal_file.name
        with open(vocal_path, "wb") as f:
            f.write(vocal_bytes)

        # Store results in session state
        st.session_state.vocal_path = vocal_path
        st.session_state.generation_complete = True
        st.session_state.current_style = singing_style
        st.session_state.current_voice = voice_option

    except Exception as e:
        st.error(f"‚ùå Generation failed: {e}")
        progress_text.text("‚ùå Generation failed")

# -------------------------
# Display Results (Persistent)
# -------------------------
def display_results():
    """Display results from session state"""
    if st.session_state.transcript:
        st.subheader("üìù Transcription Results")
        st.write(f"**Transcribed Text:** {st.session_state.transcript}")

    if st.session_state.generation_complete and st.session_state.vocal_path:
        st.subheader("üé∂ Generated Singing Voice")
        st.success(f"üé§ Generated {st.session_state.current_style} style with {st.session_state.current_voice} voice!")

        # Display audio player
        st.audio(st.session_state.vocal_path, format="audio/wav")

        # Download buttons
        col1, col2 = st.columns(2)
        with col1:
            with open(st.session_state.vocal_path, "rb") as f:
                st.download_button(
                    "üì• Download New Version", 
                    f.read(), 
                    file_name=f"singified_{st.session_state.current_style.lower()}.wav", 
                    mime="audio/wav",
                    key="download_sung"
                )
        with col2:
            if st.session_state.original_path:
                with open(st.session_state.original_path, "rb") as f:
                    st.download_button(
                        "üì• Download Old Version", 
                        f.read(), 
                        file_name="original_audio.wav", 
                        mime="audio/wav",
                        key="download_original"
                    )

# -------------------------
# Main Process Button
# -------------------------
st.subheader("üöÄ Generate Singing Voice")

if audio_bytes is not None or st.session_state.original_path:
    if not st.session_state.generation_complete:
        if st.button("üé∂ Transcribe & Sing", type="primary"):
            asyncio.run(transcribe_and_sing())
    else:
        st.info("‚úÖ Generation already completed! Results shown below.")
else:
    st.warning("‚ö†Ô∏è Please upload or record an audio file first!")

# -------------------------
# Always Display Results if Available
# -------------------------
display_results()

# -------------------------
# Instructions
# -------------------------
st.subheader("üìã How to Use")
st.markdown("""
1. **Upload** an audio file or **record** your voice using either recording option
2. Choose your preferred **singing style** and **voice** from the sidebar
3. Click **"Transcribe & Sing"** to process
4. Download your **sung version** and **original audio**
5. Use **"Generate New"** to create different versions

**Supported Formats:** WAV, MP3, M4A, OGG, FLAC  
**Max File Size:** 200MB  
**Best Results:** Clear speech, minimal background noise

**Recording Options:**
- **Native Streamlit Audio Input**: Built-in, works everywhere (recommended)
- **Enhanced Audio Recorder**: Better controls, requires package installation

**For Enhanced Recording Features:**""")